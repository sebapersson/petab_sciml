var documenterSearchIndex = {"docs":
[{"location":"format.html#Format-Specification","page":"Format","title":"Format Specification","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"A PEtab SciML problem extends the PETab a standard version problem to accommodate hybrid models SciML combining data-driven (neural net) and mechanistic components. The extension introduces one new file type:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Neural Net File(s): YAML file(s) describing neural net model(s).","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"It also extends the following standard PEtab files to accommodate SciML models:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Mapping Table: Used to describe how neural network inputs and outputs map to PEtab quantities.\nParameters Table: Used to describe nominal values and potential priors for initializing network parameters.\nCondition Table: Used to assign neural network outputs and inputs.\nProblem YAML File: Includes a new SciML field.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"All other PEtab files remain unchanged. This page explains each file that is added or modified by the PEtab SciML extension.","category":"page"},{"location":"format.html#High-Level-Overview","page":"Format","title":"High Level Overview","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The main goal of the PEtab SciML extension is to enable hybrid models that combine data-driven and mechanistic components. There are three types of hybrid model considered, each specified differently:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Data-driven models in the ODE model’s right-hand side (RHS): In this scenario, the SBML file is modified during import by either replacing a derivative or assigning a parameter to a neural network input. In both cases, the neural network inputs and outputs (as defined in the mapping table) must be assigned in the condition table using the setNetRate and/or setNetAssignment operator types.\nData-driven models in the observable function: In this scenario, the neural network output variable (as defined in the mapping table) is directly embedded in the observable formula. Meanwhile, the input variables (also defined in the mapping table) are assigned in the condition table using the setNetAssignment operator type.\nData-driven models before the ODE model: In this scenario, the data-driven model sets constant parameters or initial values in the ODE model prior to simulation. The input can be defined either in the mapping table or in the condition table, and the output variables (as defined in the mapping table) are assigned via the condition table.","category":"page"},{"location":"format.html#Neural-Network-Model-Format","page":"Format","title":"Neural Network Model Format","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"TODO: Dilan, I will need some help from you here, link the scheme?","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Neural network models are provided as separate YAML files, and each tool supporting the extension is responsible for importing this file into a suitable neural network library. Each YAML file has two main sections:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"layers: Defines the neural network layers, each with a unique ID. The layer names and argument syntax follow PyTorch conventions.\nforward: Describes the forward pass, specifying the order of layer calls and any applied activation functions.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Although network YAML files can be manually written, the recommended approach is to define a PyTorch nn.Module whose constructor sets up the layers and whose forward method specifies how they are invoked. For example, a simple feed-forward network can be defined as:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.layer1 = nn.Linear(in_features=2, out_features=5)\n        self.layer2 = nn.Linear(in_features=5, out_features=5)\n        self.layer3 = nn.Linear(in_features=5, out_features=1)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = F.tanh(x)\n        x = self.layer2(x)\n        x = F.tanh(x)\n        x = self.layer3(x)\n        return x","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The corresponding YAML file can then be generated using the petab_sciml library:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"# TODO: Add","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Any PyTorch-supported keyword can be supplied for each layer in the YAML file, allowing for a broad range of architectures. For example, a more complex convolutional model might be structured as:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.max_pool1 = nn.MaxPool2d((2, 2))\n        self.fc1 = nn.Linear(64, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        self.flatten1 = nn.Flatten()\n\n    def forward(self, input):\n        c1 = self.conv1(input)\n        s2 = self.max_pool1(c1)\n        c3 = self.conv2(s2)\n        s4 = self.max_pool1(c3)\n        s4 = self.flatten1(s4)\n        f5 = self.fc1(s4)\n        f6 = self.fc2(f5)\n        output = self.fc3(f6)\n        return output","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"A complete list of supported and tested layers and activation functions can be found [ADD].","category":"page"},{"location":"format.html#Neural-Network-Parameters","page":"Format","title":"Neural Network Parameters","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"All parameters for a neural network model are stored in an HDF5 file, with the file name specified in the parameter table. In this file, each layer’s parameters are grouped under f.layerId, where layerId is the layer’s unique identifier. For example, the weights of a linear layer are stored at f.layerId.weight.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Since parameters are stored in an HDF5 format, they are stored as arrays. The indexing follows PyTorch conventions, meaning parameters are stored in row-major order. Typically, users do not need to manage these details manually, as PEtab SciML tools should handle them automatically.","category":"page"},{"location":"format.html#Neural-Network-Input","page":"Format","title":"Neural Network Input","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"When network input is provided as an array via an HDF5 file (see the mapping table below), it should follow the PyTorch convention. For example, if the first layer is Conv2d, the input should be in (C, W, H) format, with data stored in row-major order. In general, the input should be structured to be directly compatible with PyTorch.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"tip: For developers: Respect memory order\nTools supporting the SciML extension should, for computational efficiency, reorder input data and potential layer parameter arrays to match the memory ordering of the target language. For example, PEtab.jl converts input data to column-major order, as used in Julia.","category":"page"},{"location":"format.html#Mapping-Table","page":"Format","title":"Mapping Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The mapping table describes how a neural network’s inputs and outputs map to PEtab problem variables. Each neural network input and output must be specified in the mapping table.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\ne.g. \nk1 netId.input1","category":"page"},{"location":"format.html#Detailed-Field-Descriptions","page":"Format","title":"Detailed Field Descriptions","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId [STRING]: A valid PEtab identifier not defined elsewhere in the PEtab problem. It can be referenced in the condition, measurement, parameter, and observable tables or be a file, but not in the model itself. For neural network outputs, the PEtab identifier must be assigned in the condition table, whereas for inputs, this is not required (see examples below).\nmodelEntityId [STRING]: Describes the neural network entity corresponding to the petabEntityId. Must follow the format netId.input{n} or netId.output{n}, where n is the specific input or output index.","category":"page"},{"location":"format.html#Network-with-Scalar-Inputs","page":"Format","title":"Network with Scalar Inputs","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"For networks with scalar inputs, the PEtab entity should correspond to a PEtab variable. For example, assume that the network net1 has two inputs, then a valid mapping table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_input1 net1.input1\nnet1_input2 net1.input2","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"In particular, scalar input variables can be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Parameters in the parameters table: These may be either estimated or constant.\nParameters assigned in the condition table: Here, the parameter can be assigned a constant value or mapped to a model variable expression. More details can be found in the section on the condition table.","category":"page"},{"location":"format.html#Network-with-Array-Inputs","page":"Format","title":"Network with Array Inputs","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Sometimes, such as with image data, a neural network requires array input. In these cases, the input can be specified as an HDF5 file directly in the mapping table:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\ninput_net1.hf5 net1.input1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"As mentioned in [ADD], the HDF5 file should follow PyTorch indexing and be stored in row-major order.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"When there are multiple simulation conditions that each require a different neural network array input, the mapping table should map to a PEtab variable (e.g., net1_input):","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_input net1.input1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"This variable is then assigned to specific input files via the condition table using the setValue operatorType. For a full example of a valid PEtab problem with array inputs, see [ADD].","category":"page"},{"location":"format.html#Network-Observable-Formula-Output","page":"Format","title":"Network Observable Formula Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"If the neural network output appears in the observable formula, the PEtab entity should be directly referenced in the observable formula. For example:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_output1 net1.output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"A valid observable table would then be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"observableId observableFormula\nobs1 net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"As usual, the observableFormula can be any valid PEtab equation, so net1_output1 + 1 would also be valid.","category":"page"},{"location":"format.html#Network-Scalar-Output","page":"Format","title":"Network Scalar Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"If the output does not appear in the observable, the output variable should still be defined in the mapping table:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_output1 net1.output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The output parameter (net1_output1) is then assigned in the condition table (see below).","category":"page"},{"location":"format.html#Additional-Details","page":"Format","title":"Additional Details","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Although a neural network can, in principle, accept both array and scalar inputs, this feature is not currently tested for among tools implementing the PEtab SciML extension due to it being hard to implement. However, tools are free to add this feature.","category":"page"},{"location":"format.html#Condition-Table","page":"Format","title":"Condition Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"In the PEtab SciML extension, the condition table is extended to specify how neural network outputs (and, if necessary, inputs) are assigned. Two new operatorType are introduced in the extension to support this functionality:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"setNetRate: Assigns the rate of a species to a neural network output. Here, targetValue must be a neural network output and targetId must be a model specie.\nsetNetAssignment: Assigns the input or output of a neural network in the ODE right-hand side (RHS) or also for input in the observable formula.\nInput Case: targetId is a neural network input, and targetValue can be any valid PEtab math expression that references model variables.\nOutput Case: targetId is a non-estimated ODE model parameter, and targetValue is a neural network output. This is used to assign a neural network output in the ODE model RHS.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"warn: Model structure altering conditions\nIn case setNetRate or setNetAssignment, during model import the generated model structure or observable formula is altered, basically a neural-network is inserted into the generated functions. Therefore, as unique model structures per condition are not supported in most PEtab tools, the same setAssignment or setRate assignment must be set per condition.","category":"page"},{"location":"format.html#Assigning-Neural-Network-Output","page":"Format","title":"Assigning Neural Network Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"To set a constant model parameter value before model simulations, the setValue operator type should be used. For example, if parameter p is determined by net1_output1 (mapped to a neural network output in the mapping table), a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setValue p net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"This specification allows for condition-specific assignments. For example, net1_output1 could target a different parameter in another condition or multiple parameters in the same condition.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"To set an initial value, the setInitial operator type should be used. For example, if the initial value of species X comes from net1_output1, a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setInitial X net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"To set a model derivative, the setNetRate operator type should be used. For example, if the rate of species X is given by net1_output1, a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetRate X net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"To alter the ODE RHS, the setNetAssignment operator type should be used. For example, if an ODE model parameter p should be given by net1_output1, a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetAssignment p net1_output1","category":"page"},{"location":"format.html#Assigning-Neural-Network-Input","page":"Format","title":"Assigning Neural Network Input","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"When a neural network sets a constant model parameter value or initial value, its input variable (as specified in the mapping table) is a standard PEtab entity. If that input variable is not defined in the parameter table, it should be assigned using the setValue operator type.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"When a neural network sets a model derivative or alters the ODE RHS, the input typically depends on model entities. Therefore, the input variable should be assigned using the setNetAssignment operator. For example, if neural network input net1_input1 is given by specie X, a valid condition table is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetAssignment net_input1 X","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Note, to ensure correct mapping, setNetAssignment must always be used for inputs when the neural network is part of the ODE RHS or observable formula.","category":"page"},{"location":"format.html#operatorType-Define-Hybrid-Model-Type","page":"Format","title":"operatorType Define Hybrid Model Type","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The condition table and mapping table together specify where a neural network model is located in a PEtab SciML problem. In particular:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"If all inputs use setNetAssignment and all outputs use either setNetRate or setNetAssignment, the neural network appears in the ODE RHS.\nIf all inputs use setNetAssignment and no outputs appear in the condition table, the neural network is part of the observable formula (note that the output variable must be referenced in the observable table).\nIf no inputs use setNetAssignment and all outputs use either setValue or setInitial, the neural network sets model parameters or initial values before the simulation.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"All other combinations are disallowed because they generally do not make sense in a PEtab context. For example, if inputs use setNetAssignment and outputs use setValue, parameter values prior to simulation would be set via an assignment rule consisting of model equations, which is not permitted in PEtab as assignment rules might be time-dependent. Moreover, if a parameter is to be set via an assignment rule, this should already be coded in the model. Implementations must ensure that the input combinations in the condition table are valid.","category":"page"},{"location":"format.html#Parameter-Table","page":"Format","title":"Parameter Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The parameter table follows the same format as in PEtab version 2, with a subset of fields being extended to accommodate neural network parameters and new initializationPriorType values for neural network-specific initialization. A general overview of the parameter table is available in the PEtab documentation; here, the focus is on extensions relevant to the SciML extension.","category":"page"},{"location":"format.html#Detailed-Field-Description","page":"Format","title":"Detailed Field Description","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId [String]: Identifies the neural network or a specific layer/parameter array. For example, layerId for netId can be specified using netId.layerId. A row for netId must be defined in the table. When parsing, more specific parameters (e.g., netId.layerId) take precedence for nominal values, priors, etc.\nnominalValue [String \\| NUMERIC]: Specifies neural network nominal values. This can be:\nA path to an HDF5 file that follows PyTorch syntax (recommended, see above for file format). If no file exists when the problem is imported and the parameters are set to be estimated, a file is created with randomly sampled values.\nA numeric value applied to all parameters under netId.\nestimate [0 \\| 1]: Indicates whether the parameters are estimated (1) or fixed (0). This must be consistent across layers. For example, if netId has estimate = 0, then netId.layerId must also be 0. In other words, freezing individual network parameters is not allowed.\ninitializationPriorType [String, OPTIONAL]: Specifies the prior used for sampling initial values before parameter estimation. In addition to the PEtab-supported priors [ADD], the SciML extension supports the following standard neural network initialization priors:\nkaimingUniform (default) — with gain as initializationPriorParameters value.\nkaimingNormal — with gain as initializationPriorParameters value.\nxavierUniform — with gain as initializationPriorParameters value.\nxavierNormal — with gain as initializationPriorParameters value.","category":"page"},{"location":"format.html#Different-Priors-for-Different-Layers","page":"Format","title":"Different Priors for Different Layers","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Different layers can be defined for different layers. For example, consider a neural-network model net1 where layer1 and layer2 should have different initializationPriorParameters, because they use different activation functions that should distinct gain for the kaimingUniform prior. A valid parameter table:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId parameterScale lowerBound upperBound estimate nominalValue initializationPriorType initializationPriorParameters\nnet1 lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer1 lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer2 lin -inf inf 1 net1_ps.hf5 kaimingUniform 5/3","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"If is also possible to have different priors for different parameter arrays in a layer. For example, to use different priors for the weights and bias in layer1 of net1, which is, for instance, a linear layer. In this case, a valid parameter table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId parameterScale lowerBound upperBound estimate nominalValue initializationPriorType initializationPriorParameters\nnet1 lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer1.weight lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer1.bias lin -inf inf 1 net1_ps.hf5 kaimingNormal 5/3","category":"page"},{"location":"format.html#Bounds-for-neural-net-parameters","page":"Format","title":"Bounds for neural net parameters","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Bounds can be specified for an entire network or its nested levels. However, it should be noted that most optimization algorithms used for neural networks, such as ADAM, do not support parameter bounds in their standard implementation.","category":"page"},{"location":"format.html#Problem-YAML-File","page":"Format","title":"Problem YAML File","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The PEtab problem YAML file follows the format of PEtab version 2, except that a mapping table is required (it is optional in the standard). It also includes an extension section to specify the neural network YAML files:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"extensions:\n  petab_sciml:\n    netId1:\n      file: \"file_path1.yaml\"\n    netId2:\n      file: \"file_path2.yaml\"","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Here, netId1 and netId2 are the IDs of the neural network models. Note that any number of neural networks can be specified. FOr example, for a model with one neural network, with ID net1, a valid YAML file would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"format_version: 2\nproblems:\n  - model_files:\n      model_sbml:\n        location: \"model.xml\"\n        language: \"sbml\"\n    measurement_files:\n      - \"measurements.tsv\"\n    observable_files:\n      - \"observables.tsv\"\n    condition_files:\n      - \"conditions.tsv\"\n    mapping_files:\n      - \"mapping_table.tsv\"\nparameter_file: \"parameters.tsv\"\nextensions:\n  petab_sciml:\n    net1:\n      file: \"net1.yaml\"","category":"page"},{"location":"index.html#PEtab-SciML-Extension","page":"Home","title":"PEtab SciML Extension","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"The PEtab SciML extension expands the PEtab parameter estimation standard to accommodate hybrid models that combine data-driven neural network models with mechanistic Ordinary Differential Equation (ODE) models. This enables a reproducible format for specifying and ultimately fitting hybrid models to time-lapse data. This repository contains both the format specification and a Python library for exporting neural network models to a standard YAML format, which can be imported across multiple programming languages.","category":"page"},{"location":"index.html#Major-Highlights","page":"Home","title":"Major Highlights","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"A format which supports three approaches for combining mechanistic and neural network models:\nIncorporating neural network model(s) data-driven model in the ODE model right-hand side.\nIncorporating neural network model(s) in the observable formula which describes the mapping between simulation output and measurement data.\nIncorporating neural network model(s) to set constant model parameter values prior to simulation, allowing for example, available metadata to be used to set parameter values.\nFormat which supports many neural network architectures, including most standard layers and activation functions available in packages such as PyTorch.\nFormat supported in tools across several programming languages. In particular, both PEtab.jl in Julia and AMICI in Python (Jax) can import problems in the PEtab SciML format.\nAn extensive test suite ensures the correctness of tools supporting the format.","category":"page"},{"location":"index.html#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"TODO: Dilan please help here.","category":"page"},{"location":"index.html#Getting-help","page":"Home","title":"Getting help","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"If you have any problems with either using this package, or with creating a PEtab SciML problem, here are some helpful tips:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"Please open an issue on GitHub.\nPost your questions in the #sciml-sysbio channel on the Julia Slack. While this is not a Julia package, the developers are active on that forum.","category":"page"},{"location":"tutorial.html#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"The tutorials will consist of:","category":"page"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"Overarching tutorial where we show how to Lotka-Voltera problem from the UDE paper.\nExtended tutorial 1 where we have a neural-network setting parameters, here it is also worthwhile to consider simulation conditions.\nExtended tutorial 2 where we have a neural network in the observable function.","category":"page"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"If time, add tutorial for having two neural networks.","category":"page"}]
}
