{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net id `net1` and MLModelId `model1` do not match. Is that ony in my LV example? Check Sebastian's test cases and the format.\n",
    "These should match because ude_problem.hybridization is a dict while the nets are a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import petab_sciml\n",
    "import nnUDE\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "from nnUDE.neural_network import (\n",
    "    Node, \n",
    "    Layer,\n",
    "    NeuralNetwork,\n",
    "    input_layer_from_species_ids\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/maren/petab_sciml/test_cases/published/lv_001/problem_ude.yaml')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_problem_yaml = (\n",
    "    Path(\".\").resolve().parents[4] /\n",
    "    \"test_cases\" /\n",
    "    \"published\" / \n",
    "    \"lv_001\" / \n",
    "    \"problem_ude.yaml\"\n",
    ")\n",
    "fp_problem_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'net1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_yaml['extensions']['petab_sciml']['net_files'][0][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import into petab_sciml\n",
    "\n",
    "# import ude problem\n",
    "with open(fp_problem_yaml) as stream:\n",
    "    problem_yaml = yaml.safe_load(stream)\n",
    "\n",
    "# get mapping table\n",
    "fp_map_yaml = (\n",
    "    fp_problem_yaml.parent / \n",
    "    problem_yaml['problems'][0]['mapping_tables']\n",
    ")\n",
    "mapping_table = pd.read_csv(fp_map_yaml, sep=\"\\t\")\n",
    "inputs = mapping_table[\n",
    "    mapping_table[\"ioId\"].str.contains(\"input\")\n",
    "][\"ioValue\"].to_list()\n",
    "outputs = mapping_table[\n",
    "    mapping_table[\"ioId\"].str.contains(\"output\")\n",
    "][\"ioValue\"].to_list()\n",
    "\n",
    "# get NN specification\n",
    "fn_net = problem_yaml['extensions']['petab_sciml']['net_files'][0]\n",
    "fp_net_yaml = fp_problem_yaml.parent / fn_net\n",
    "with open(fp_net_yaml) as stream:\n",
    "    net1_yaml = yaml.safe_load(stream)\n",
    "\n",
    "net_id = fn_net[:-5]\n",
    "nn_model = net1_yaml['models'][0]\n",
    "\n",
    "# ensure it's a FFNN\n",
    "for layer in nn_model[\"layers\"]:\n",
    "    assert layer['layer_type'] == 'Linear', \\\n",
    "        f\"Non-linear layer: {layer}\"\n",
    "\n",
    "ff_architecture = nn_model[\"forward\"]\n",
    "# first layer item should be a placeholder\n",
    "assert ff_architecture[0]['op'] == 'placeholder', \\\n",
    "        f\"First op is not 'placeholder': {nn_model['forward'][0]}\"\n",
    "\n",
    "# Is there an input transformation?\n",
    "# corresp. to a function in second item\n",
    "if ff_architecture[1]['op'] == \"call_method\":\n",
    "    act = ff_architecture[1]['target']\n",
    "    i = 2\n",
    "elif ff_architecture[1]['op'] == \"call_module\":\n",
    "    act = None\n",
    "    i = 1\n",
    "else:\n",
    "    raise KeyError(f\"Not a valid op: {ff_architecture[1]['op']}\")\n",
    "\n",
    "# get nUDE input layer\n",
    "input_layer = input_layer_from_species_ids(\n",
    "        neural_network_id=net1_yaml['models'][0]['mlmodel_id'],\n",
    "        species_ids=inputs,\n",
    "        # to do: allow input transformation = activation function\n",
    "        # act\n",
    "    )\n",
    "\n",
    "# iterate over items in forward\n",
    "# ensure at most one activation function between layers\n",
    "constructed_layers = [input_layer]\n",
    "\n",
    "while i < len(ff_architecture):\n",
    "    # get layer id\n",
    "    layer_id = ff_architecture[i]['name']\n",
    "    layer_index_num = len(constructed_layers)\n",
    "    nodes = []\n",
    "    layer_info = [d for d in nn_model[\"layers\"] if d['layer_id'] == layer_id][0]['args']\n",
    "    # check for activation function\n",
    "    if ff_architecture[i+1]['op'] == \"call_method\":\n",
    "        layer_info['activation'] = ff_architecture[1]['target']\n",
    "        i += 2\n",
    "    elif ff_architecture[i+1]['op'] == \"call_module\":\n",
    "        layer_info['activation'] = None\n",
    "        i += 1\n",
    "    elif ff_architecture[i+1]['op'] == \"output\":\n",
    "        layer_info['activation'] = None\n",
    "        i += 2\n",
    "    else:\n",
    "        raise KeyError(f\"Not a valid op: {ff_architecture[i+1]['op']}\")\n",
    "    # To Do: call the NUDE layer construction function\n",
    "    for node_index in range(layer_info['out_features']):\n",
    "        node = Node(\n",
    "            id_=f\"{net_id}__layer_{layer_index_num}__node__{node_index}\",\n",
    "            index=node_index,\n",
    "            input_nodes=constructed_layers[-1].nodes,\n",
    "            activation_function=layer_info['activation'],\n",
    "        )\n",
    "        nodes.append(node)\n",
    "\n",
    "    layer = Layer(\n",
    "        id_=f\"{net_id}__layer_{layer_id}\",\n",
    "        index=layer_index_num,\n",
    "        nodes=nodes,\n",
    "    )\n",
    "    constructed_layers.append(layer)\n",
    "\n",
    "# if i == len(ff_architecture):\n",
    "#     if ff_architecture[i] == \"output\":\n",
    "#         pass\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unexpected last item: {ff_architecture[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = NeuralNetwork(\n",
    "    id_=net_id,\n",
    "    input_layer=constructed_layers[0],\n",
    "    layers=constructed_layers[1:],\n",
    "    output_species_ids=outputs,\n",
    "    regularization=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(id_='net1', input_layer=Layer(id_='neural_network_net1__layer_input', index=None, nodes=[Node(id_='prey', index=0, input_nodes=None, activation_function=None, formula='prey'), Node(id_='predator', index=1, input_nodes=None, activation_function=None, formula='predator')]), output_species_ids=['prey_predation', 'predator_predation'], layers=[Layer(id_='net1__layer_layer1', index=1, nodes=[Node(id_='net1__layer_1__node__0', index=0, input_nodes=[Node(id_='prey', index=0, input_nodes=None, activation_function=None, formula='prey'), Node(id_='predator', index=1, input_nodes=None, activation_function=None, formula='predator')], activation_function='layer1', formula=None), Node(id_='net1__layer_1__node__1', index=1, input_nodes=[Node(id_='prey', index=0, input_nodes=None, activation_function=None, formula='prey'), Node(id_='predator', index=1, input_nodes=None, activation_function=None, formula='predator')], activation_function='layer1', formula=None)]), Layer(id_='net1__layer_layer2', index=2, nodes=[Node(id_='net1__layer_2__node__0', index=0, input_nodes=[Node(id_='net1__layer_1__node__0', index=0, input_nodes=[Node(id_='prey', index=0, input_nodes=None, activation_function=None, formula='prey'), Node(id_='predator', index=1, input_nodes=None, activation_function=None, formula='predator')], activation_function='layer1', formula=None), Node(id_='net1__layer_1__node__1', index=1, input_nodes=[Node(id_='prey', index=0, input_nodes=None, activation_function=None, formula='prey'), Node(id_='predator', index=1, input_nodes=None, activation_function=None, formula='predator')], activation_function='layer1', formula=None)], activation_function=None, formula=None), Node(id_='net1__layer_2__node__1', index=1, input_nodes=[Node(id_='net1__layer_1__node__0', index=0, input_nodes=[Node(id_='prey', index=0, input_nodes=None, activation_function=None, formula='prey'), Node(id_='predator', index=1, input_nodes=None, activation_function=None, formula='predator')], activation_function='layer1', formula=None), Node(id_='net1__layer_1__node__1', index=1, input_nodes=[Node(id_='prey', index=0, input_nodes=None, activation_function=None, formula='prey'), Node(id_='predator', index=1, input_nodes=None, activation_function=None, formula='predator')], activation_function='layer1', formula=None)], activation_function=None, formula=None)])], regularization=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
